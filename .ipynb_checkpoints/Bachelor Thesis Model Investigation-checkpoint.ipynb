{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import shap\n",
    "import sklearn\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from general_code import datasets, functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors, DistanceMetric\n",
    "from datetime import datetime\n",
    "from statistics import mode, median, mean \n",
    "from importlib import reload  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'general_code' in sys.modules:  \n",
    "    del sys.modules[\"general_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the use of SHAP values to existing fairness measures\n",
    "\n",
    "### Current work on fairness\n",
    "\n",
    "As the use of decision making algorithms is increasing, so does the want for a proof of fairness of these algorithms. The discussion about many different possible fairness measures is therefore rising as well. \n",
    "\n",
    "### Current work on SHAP\n",
    "\n",
    "Apart from the need to verify the fairness of an algorithm, understanding its workings is of great importance as well. Of the currently available methods, SHAP is the most unified approach.\n",
    "\n",
    "### The models \n",
    "\n",
    "To explore the usefulness of SHAP in fairness assessment, two classification models were created. One model is based on the COMPAS dataset and predicts recidivism and the second model is based on the German Credit Risk dataset and predicts the risk of giving a loan. \n",
    "\n",
    "### Methods to improve or enhance fairness measures:\n",
    "#### 1. Correlation between SPD and SHAP values\n",
    "#### 2. Using SHAP distance to compute Individual Fairness\n",
    "#### 3. Explaining existing methods with SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The models\n",
    "\n",
    "The models were made using existing datasets which are known to be biased, thus creating biased models as well. The models are both random forest models, created with the RandomForestClassifier from the scikit-learn library. To make the data suitable for such a model, it was first preproccesed. This preprocessing consisted of making the data numerical and of appropriate format.\n",
    "\n",
    "The recidivism model is based on 33 attributes and consists of 8952 samples. The output is 0 (will not recidivate) or 1 (will recidivate). The credit model is based on 38 attributes and consists of 1000 samples. The output is 0 (low risk) or 1 (high risk).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset, include_sex = True):\n",
    "    if dataset == 'compas':\n",
    "        protected_att = ['sex_male', 'race_black']\n",
    "        return datasets.compas(include_sex)\n",
    "    elif dataset == 'german_credit':\n",
    "        protected_att = ['f_div/sep/mar']\n",
    "        return datasets.german_credit(include_sex)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = get_data('german_credit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[139  12]\n",
      " [ 33  16]]\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the random forest regression algorithm:\n",
    "model = RandomForestClassifier(max_depth=6, random_state=0, n_estimators=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model:\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n"
     ]
    }
   ],
   "source": [
    "#Calculate SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "global_shap_values = shap_values[1].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to improve or enhance fairness measures:\n",
    "### 1. Correlation between fairness measures and SHAP values\n",
    "One way the SHAP values could prove to be usefull is if they could be used to replace existing measures. The intuitive nature of SHAP values could make them a better alternative than the existing measures. To find out whether the SHAP values are in some way related to the measures, the correlation between them is calculated. \n",
    "\n",
    "**Statistical Parity:**\n",
    "\n",
    "The first fairness measure that was compared to SHAP values is the notion of statistical parity (also called group fairness, equal acceptance rate or benchmarking). This notion is satisfied if all groups have equal outcomes. The statistical parity difference (SPD) is then a measure of the difference of outcomes between groups. If all groups have similar outputs, that means that the attribute that devides these groups should have no impact on the output of the model. The impact on the model can be measured with SHAP values. It would therefore be a logical conclusion that if the SPD is low, the protected attribute should also have a low general SHAP value. We would thus expect to find a correlation between the SPD when split on a certain attribute and the general SHAP value of this attribute. \n",
    "\n",
    "To test this hypothesis, the SPD and the general SHAP value are computed for all the attributes. Many of the attributes are not so called 'protected attributes', but the same behaviour is expected for attributes that are not considered 'protected'. To enable splitting the data on an attribute, the non-binary variables are split on the median value. One groups is thus the group with the 'low value' for the attribute and the other has the 'high value'. The SPD and the SHAP value of each attribute are computed and plotted against each other. The Pearson correlation coefficient will then show the correlation between the two variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.34552247]\n",
      " [-0.34552247  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def compute_spd_shap_bin(attribute, val1=0, val2=1):\n",
    "    #Split data\n",
    "    _, _, _, _, y_pred_a, _, _, _, _, y_pred_b =  functions.split_data(X_train, y_train, X_test, y_test, model, attribute, val1=val1, val2=val2)\n",
    "    #Compute spd\n",
    "    spd = functions.statistical_parity_difference(y_pred_a, y_pred_b)\n",
    "    #Get global SHAP\n",
    "    att_idx = X_train.columns.get_loc(attribute)\n",
    "    shap = global_shap_values[att_idx]\n",
    "    return spd, shap\n",
    "\n",
    "def compute_spd_shap_nonbin(attribute, indices_test):\n",
    "    #Split data\n",
    "    X_test_a = X_test.loc[indices_test == 0]\n",
    "    X_test_b = X_test.loc[indices_test == 1]\n",
    "    y_pred_a = model.predict(X_test_a)\n",
    "    y_pred_b = model.predict(X_test_b)\n",
    "    #Compute spd\n",
    "    spd = functions.statistical_parity_difference(y_pred_a, y_pred_b)\n",
    "    #Get global SHAP\n",
    "    att_idx = X_train.columns.get_loc(attribute)\n",
    "    shap = global_shap_values[att_idx]\n",
    "    return spd, shap\n",
    "\n",
    "#Find which columns are binary and which are not\n",
    "bin_columns = []\n",
    "nonbin_columns = []\n",
    "for col in X_train.columns:\n",
    "    binary = True\n",
    "    for i in X_train[col]:\n",
    "        if i!=1 and i!=0:\n",
    "            binary = False\n",
    "    if binary == True:\n",
    "        bin_columns.append(col)\n",
    "    else:\n",
    "        nonbin_columns.append(col)\n",
    "\n",
    "#Save for all non-binary attributes whether a sample is low or high\n",
    "low_indices_test = np.zeros((np.shape(X_test)[0], np.shape(nonbin_columns)[0]))\n",
    "for col_idx, col in enumerate(nonbin_columns):\n",
    "    median_val = median(X_train[col])\n",
    "    for idx, i in enumerate(X_test[col]):\n",
    "        if i <= median_val:\n",
    "            low_indices_test[idx, col_idx] = 0\n",
    "        else:\n",
    "            low_indices_test[idx, col_idx] = 1\n",
    "\n",
    "#Compute the SPD and SHAP for all these attributes\n",
    "spd_vals = np.zeros(np.shape(bin_columns)[0] + np.shape(nonbin_columns)[0])\n",
    "shap_vals = np.zeros(np.shape(bin_columns)[0] + np.shape(nonbin_columns)[0])\n",
    "\n",
    "for idx, col in enumerate(bin_columns):\n",
    "    spd_vals[idx], shap_vals[idx] = compute_spd_shap_bin(col)\n",
    "for idx, col in enumerate(nonbin_columns):\n",
    "    spd_vals[np.shape(bin_columns)[0]+idx], shap_vals[np.shape(bin_columns)[0]+idx] = compute_spd_shap_nonbin(col, low_indices_test[:, idx])\n",
    "\n",
    "#Plot the SPD and SHAP\n",
    "plt.plot(spd_vals, shap_vals, 'ro')\n",
    "plt.xlabel('spd')\n",
    "plt.ylabel('shap')\n",
    "plt.show()\n",
    "\n",
    "corrcoef = np.corrcoef(spd_vals, shap_vals)\n",
    "print(corrcoef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using SHAP distance to compute Individual Fairness\n",
    "\n",
    "Another way SHAP can be of use, is to improve an existing fairness measure. One fairness measure which could be improved using SHAP is the notion of Individual Fairness. An algorithm satisfies this notion of fairness if similar samples have similar output. Different metrics can be used to determine the similarity between samples. Most of the time, the similarity is computed based on the features. If two samples have similar features, the samples are considered similar as well. However, the features are often on different scale, which makes it difficult to compute similarity of such different features. To improve this notion of Individual Fairness, the similarity of samples can also be computed using SHAP values. If two samples have similar SHAP values, the samples are considered similar as well. Because SHAP values all have the same unit, determining similarity will become easier and more accurate. \n",
    "\n",
    "To test whether the use of SHAP values in this context truly improves the notion of Individual Fairness, certain aspects are looked at. First, the individuals who do not receive individual fairness are analyzed. These individuals can receive either a positive or negative bias. The expectation is that certain groups that have proven to be treated unfair, also receive unfair treatment based on the notion of Individual Fairness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of (the indices of) similair sample pairs\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X_test_scaled)\n",
    "distances, indices = nbrs.kneighbors(X_test_scaled)\n",
    "\n",
    "indices_maxdist_list = []\n",
    "\n",
    "for idx, item in enumerate(indices):\n",
    "    if distances[idx, 1] <= 4:\n",
    "        indices_maxdist_list.append(item)\n",
    "\n",
    "print(np.shape(indices))\n",
    "print(np.shape(indices_maxdist_list)) \n",
    "similar_samples = np.array(indices_maxdist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(l1, l2):\n",
    "    return math.sqrt(sum([(a - b) ** 2 for a, b in zip(l1, l2)]))\n",
    "\n",
    "threshold=0.1\n",
    "conf_matrix = np.zeros((2,2))\n",
    "for idx, [i, j] in enumerate(similar_samples):\n",
    "    shap_dist = euclidean_distance(shap_values[1][i], shap_values[1][j])\n",
    "    if y_pred[i] == y_pred[j] and shap_dist <= threshold:\n",
    "        conf_matrix[0][0] = conf_matrix[0][0] + 1\n",
    "    elif y_pred[i] != y_pred[j] and shap_dist <= threshold:\n",
    "        conf_matrix[0][1] = conf_matrix[0][1] + 1\n",
    "    elif y_pred[i] == y_pred[j] and shap_dist > threshold:\n",
    "        conf_matrix[1][0] = conf_matrix[1][0] + 1\n",
    "    elif y_pred[i] != y_pred[j] and shap_dist > threshold:\n",
    "        conf_matrix[1][1] = conf_matrix[1][1] + 1\n",
    "\n",
    "[[TP,FN],[FP,TN]] = conf_matrix\n",
    "\n",
    "accuracy = (TP + TN)/(TP+FN+FP+TN)\n",
    "\n",
    "print(accuracy)\n",
    "print(np.shape(similar_samples)) \n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eucl_dist = [euclidean_distance(shap_values[1][i], shap_values[1][j]) for i,j in indices]\n",
    "fig = plt.figure()\n",
    "plt.plot(eucl_dist, distances[:,1], 'ro', markersize=4)\n",
    "#plt.yscale('symlog')\n",
    "plt.xlabel(\"Euclidean distance SHAP\")\n",
    "plt.ylabel(\"distance samples\")\n",
    "plt.title(\"Relation between the difference of the samples and the difference of the SHAP values for most similair pairs\")\n",
    "fig.savefig(\"Individual_fairness_credit.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Individual Fairness with d(i,j) = euclidean_distance(i,j)\n",
    "nbrs = NearestNeighbors(n_neighbors=4, algorithm='ball_tree').fit(X_test_scaled)\n",
    "_, indices_orig = nbrs.kneighbors(X_test_scaled)\n",
    "\n",
    "consistency_orig, negative_bias_orig, positive_bias_orig = consistency(X_test, y_pred, indices_orig)\n",
    "\n",
    "#Calculate Individual fairness with d(i,j) = euclidean_distance(shap(i), shap(j))\n",
    "def shap_dist(x,y):\n",
    "    shap_values_x = explainerModel.shap_values(x)\n",
    "    shap_values_y = explainerModel.shap_values(y)\n",
    "    return euclidean_distance(shap_values_x[1], shap_values_y[1])\n",
    "    \n",
    "nbrs = NearestNeighbors(n_neighbors=4, algorithm='ball_tree', metric= shap_dist ).fit(X_test_scaled)\n",
    "distances_shap, indices_shap = nbrs.kneighbors(X_test_scaled)\n",
    "\n",
    "consistency_shap, negative_bias_shap, positive_bias_shap = consistency(X_test, y_pred, indices_shap)\n",
    "\n",
    "print(consistency_orig)\n",
    "print(consistency_shap)\n",
    "\n",
    "print(np.shape(negative_bias_orig), np.shape(positive_bias_orig))\n",
    "print(np.shape(negative_bias_shap), np.shape(positive_bias_shap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bias(negative_bias, positive_bias):\n",
    "    female_neg = 0\n",
    "    male_neg = 0\n",
    "    for idx, i in enumerate(negative_bias):\n",
    "        if i['f_div/sep/mar'] ==1:\n",
    "            female_neg += 1\n",
    "        else:\n",
    "            male_neg += 1\n",
    "    female_pos = 0\n",
    "    male_pos = 0       \n",
    "    for idx, i in enumerate(positive_bias):\n",
    "        if i['f_div/sep/mar'] ==1:\n",
    "            female_pos += 1\n",
    "        else:\n",
    "            male_pos += 1\n",
    "    female_ratio =female_neg/(female_pos+female_neg)\n",
    "    male_ratio = male_neg/(male_pos+male_neg)\n",
    "    \n",
    "    print('pos/neg bias for male: ', male_pos, male_neg)\n",
    "    print('pos/neg bias for female: ', female_pos, female_neg)\n",
    "\n",
    "    return female_ratio, male_ratio\n",
    "\n",
    "female_ratio_orig, male_ratio_orig = check_bias(negative_bias_orig, positive_bias_orig)\n",
    "female_ratio_shap, male_ratio_shap = check_bias(negative_bias_shap, positive_bias_shap)\n",
    "print(female_ratio_orig, male_ratio_orig)\n",
    "print(female_ratio_shap, male_ratio_shap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protected attribute: Gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = split_data(X_train, y_train, X_test, y_test, model, 'f_div/sep/mar')\n",
    "X_train_female, y_train_female, X_test_female, y_test_female, y_pred_female, X_train_male, y_train_male, X_test_male, y_test_male, y_pred_male = data_split\n",
    "\n",
    "spd = statistical_parity_difference(y_pred_male, y_pred_female)\n",
    "print(spd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model, shap.sample(X_train,100))\n",
    "shap_values = explainer.shap_values(X_test, y_pred)\n",
    "global_shap_values = np.abs(shap_values[1]).mean(0)\n",
    "shap.summary_plot(shap_values[1], X_test, plot_type = 'bar', show=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining fairness with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(att, val, x_label, size):\n",
    "    plt.rcdefaults()\n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    ax.barh(np.arange(len(att)), val, align='center', height=0.8,)\n",
    "    ax.set_yticks(np.arange(len(att)))\n",
    "    ax.set_yticklabels(att)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel(x_label)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Statistical parity difference Men vs Woman:\n",
    "data_split = split_data(X_train, y_train, X_test, y_test, model, 'f_div/sep/mar')\n",
    "X_train_female, y_train_female, X_test_female, y_test_female, y_pred_female, X_train_male, y_train_male, X_test_male, y_test_male, y_pred_male = data_split\n",
    "y_pred_prob_male = model.predict_proba(X_test_male)[:,1]\n",
    "y_pred_prob_female = model.predict_proba(X_test_female)[:,1]\n",
    "\n",
    "spd = statistical_parity_difference(y_pred_male, y_pred_female)\n",
    "spd_prob = statistical_parity_difference(y_pred_prob_male, y_pred_prob_female)\n",
    "\n",
    "bar_plot([\"model output\", \"model probability output\"], [spd, spd_prob], 'Statistical parity difference of model output (men vs women)', (10,1))\n",
    "print(\"Negative values mean that women have a higher average predicted outcome than men\")\n",
    "print(spd, spd_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_female = []\n",
    "shap_values_male = []\n",
    "is_female = np.asarray(X_test[\"f_div/sep/mar\"])\n",
    "for idx, i in enumerate(shap_values[1]):\n",
    "    if is_female[idx] == 1:\n",
    "        shap_values_female.append(i)\n",
    "    else:\n",
    "        shap_values_male.append(i)\n",
    "    \n",
    "\n",
    "shap_values_male = np.asarray(shap_values_male)\n",
    "shap_values_female = np.asarray(shap_values_female)\n",
    "att = np.asarray(X_train.columns)\n",
    "val = []\n",
    "for i in range(len(att)):\n",
    "    spd = statistical_parity_difference(shap_values_male[:,i], shap_values_female[:,i])\n",
    "    val.append(spd)\n",
    "            \n",
    "bar_plot(att, val, 'Statistical parity difference of SHAP values (men vs women)', (10,10))\n",
    "sum = 0\n",
    "for i in val:\n",
    "    sum+=i\n",
    "print(sum)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
